{
 "metadata": {
  "name": "",
  "signature": "sha256:a7d8ee6ed7080e608dcd2d19113da8e7788c1e87395dd734f7403a72e3e535f3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Method of multipliers"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The method of multipliers is an algorithm for solving convex optimization problems. \n",
      "Suppose we have a problem of the form\n",
      "\n",
      "\\begin{array}{ll}\n",
      "\\mbox{minimize} & f(x)\\\\\n",
      "\\mbox{subject to} & Ax = b,\n",
      "\\end{array}\n",
      "\n",
      "where $f$ is convex, $x \\in \\mathbf{R}^n$ is the optimization variable, and $A \\in \\mathbf{R}^{m \\times n}$ and $b \\in \\mathbf{R}^m$ are problem data.\n",
      "\n",
      "To apply the method of multipliers, we first form the augmented Lagrangian \n",
      "\n",
      "$$L_{\\rho}(x,y) = f(x) + y^T(Ax - b) + (\\rho/2)\\|Ax-b\\|^2_2.$$\n",
      "\n",
      "The dual function associated with the augmented Lagrangian is $g_{\\rho}(y) = \\inf_x L_{\\rho}(x,y)$. \n",
      "The dual function $g_{\\rho}(y)$ is concave and its maximal value is the same as the optimal value of the original problem.\n",
      "\n",
      "We maximize the dual function using gradient ascent. Each step of gradient ascent reduces to the $x$ and $y$ updates\n",
      "\n",
      "\\begin{array}{lll}\n",
      "x^{k+1} & := & \\mathop{\\rm argmin}_{x}\\left(f(x) + (y^k)^T(Ax - b) + (\\rho/2)\\left\\|Ax-b\\right\\|^2_2 \\right) \\\\\n",
      "y^{k+1} & := & y^{k} + \\rho(Ax^{k+1}-b)\n",
      "\\end{array}\n",
      "\n",
      "The optimization problem in the $x$ update is known as a proximal operator. For many $f$, solving the optimization problem, or evaluating the proximal operator, is very efficient.\n",
      "See [this paper](http://web.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf) for more information about the method of multipliers and proximal operators.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following CVXPY script implements the method of multipliers and uses it to solve an optimization problem."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cvxpy import *\n",
      "import numpy as np\n",
      "np.random.seed(1)\n",
      "\n",
      "# Initialize data.\n",
      "MAX_ITERS = 100\n",
      "rho = 1.0\n",
      "n = 20\n",
      "m = 10\n",
      "A = np.random.randn(m,n)\n",
      "b = np.random.randn(m,1)\n",
      "\n",
      "# Initialize problem.\n",
      "x = Variable(n)\n",
      "f = norm(x, 1)\n",
      "\n",
      "# Solve with CVXPY.\n",
      "Problem(Minimize(f), [A*x == b]).solve()\n",
      "print \"Optimal value from CVXPY\", f.value\n",
      "\n",
      "# Solve with method of multipliers.\n",
      "resid = A*x - b\n",
      "y = Parameter(m); y.value = np.zeros(m)\n",
      "aug_lagr = f + y.T*resid + (rho/2)*sum_squares(resid)\n",
      "for t in range(MAX_ITERS):\n",
      "    Problem(Minimize(aug_lagr)).solve()\n",
      "    y.value += rho*resid.value\n",
      "    \n",
      "print \"Optimal value from method of multipliers\", f.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimal value from CVXPY 5.57311224497\n",
        "Optimal value from method of multipliers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5.57276163655\n"
       ]
      }
     ],
     "prompt_number": 19
    }
   ],
   "metadata": {}
  }
 ]
}