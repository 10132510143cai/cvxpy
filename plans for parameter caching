plans for parameter caching:

class ProblemCache(c, A, b, G=G, h=h)

{solver: ProblemCache}
attributes
obj_offset, A, G - (V,I,J) triplets.
c, b, h - NumPy ndarrays
objective: obj_offset, c
eq_constr: A, b
ineq_constr: G, h
cached_constr = set of constraint ids that have been cached.

stuff_matrix file for constr_matrix, merge_nonlin
break out constraint processing into

const_vec = ProblemCache.?
V, I, J = ProblemCache.?
for constr in constraints:
    if constr.constr_id not in cached_constr:
       V, I, J = process_constr(constr, var_offsets, const_vec, vert_offset)
       if not get_expr_params(constr.expr):
          add constr.constr_id to set
          add V, I, J to cache
vert_offset += constr.size[0]*constr.size[1]

constr_matrix to lin_matrix
merge_nonlin to nonlin_matrix

ProblemCache(objective, eq_constr, ineq_constr, nonlin_constr)
processes these and creates c, obj_offset, A, b, G, h, F
MatrixData instead of ProblemCache?
Give parameters to ProblemCache or have function
A, b = prob_cache.get_eq_constr()  evaluates params.
constr_id -> V, I, J, const_vec
prob_cache.coeff(constr)

id for all expressions? Then get objective too.
better not to cache more than coeffs because could change objective and constraints

matrix_stuffing

lin_matrix
nonlin_matrix


Making problems immutable:
tuple of constraints internally (@property)
objective immutable

Then in best case cache all mats for each solver.

Make solver class for solve and problem_data methods. !!!